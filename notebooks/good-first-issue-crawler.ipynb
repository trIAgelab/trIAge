{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good First Issue Crawler"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preamble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from github import Github\n",
    "from tqdm import tqdm\n",
    "from loguru import logger"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Workflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[32m2023-06-17 19:43:26.253\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_github_instance\u001b[0m:\u001b[36m4\u001b[0m - \u001b[1mGitHub instance initialized\u001b[0m\n",
      "\u001b[32m2023-06-17 19:43:26.254\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mget_repositories\u001b[0m:\u001b[36m8\u001b[0m - \u001b[1mFetching specified repositories\u001b[0m\n",
      "Processing repositories:   0%|          | 0/22 [00:00<?, ?it/s]\u001b[32m2023-06-17 19:43:36.208\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: matplotlib/matplotlib\u001b[0m\n",
      "Processing repositories:   5%|▍         | 1/22 [01:01<21:29, 61.38s/it]\u001b[32m2023-06-17 19:44:37.591\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: einsteinpy/einsteinpy\u001b[0m\n",
      "Processing repositories:   9%|▉         | 2/22 [01:05<09:18, 27.91s/it]\u001b[32m2023-06-17 19:44:42.064\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: zulip/zulip\u001b[0m\n",
      "Processing repositories:  14%|█▎        | 3/22 [02:49<19:44, 62.34s/it]\u001b[32m2023-06-17 19:46:25.382\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: falconry/falcon\u001b[0m\n",
      "Processing repositories:  18%|█▊        | 4/22 [03:00<12:42, 42.36s/it]\u001b[32m2023-06-17 19:46:37.104\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: dmlc/gluon-nlp\u001b[0m\n",
      "Processing repositories:  23%|██▎       | 5/22 [03:13<08:56, 31.57s/it]\u001b[32m2023-06-17 19:46:49.554\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: mesonbuild/meson\u001b[0m\n",
      "Processing repositories:  27%|██▋       | 6/22 [04:14<11:05, 41.59s/it]\u001b[32m2023-06-17 19:47:50.592\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: scipy/scipy\u001b[0m\n",
      "Processing repositories:  32%|███▏      | 7/22 [05:03<11:00, 44.04s/it]\u001b[32m2023-06-17 19:48:39.669\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: oilshell/oil\u001b[0m\n",
      "Processing repositories:  36%|███▋      | 8/22 [05:20<08:15, 35.41s/it]\u001b[32m2023-06-17 19:48:56.620\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: google/TensorNetwork\u001b[0m\n",
      "Processing repositories:  41%|████      | 9/22 [05:29<05:52, 27.11s/it]\u001b[32m2023-06-17 19:49:05.465\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: statsmodels/statsmodels\u001b[0m\n",
      "Processing repositories:  45%|████▌     | 10/22 [06:25<07:13, 36.12s/it]\u001b[32m2023-06-17 19:50:01.762\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: ray-project/ray\u001b[0m\n",
      "Processing repositories:  50%|█████     | 11/22 [08:06<10:16, 56.03s/it]\u001b[32m2023-06-17 19:51:42.935\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: cython/cython\u001b[0m\n",
      "Processing repositories:  55%|█████▍    | 12/22 [08:45<08:27, 50.76s/it]\u001b[32m2023-06-17 19:52:21.641\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: automl/auto-sklearn\u001b[0m\n",
      "Processing repositories:  59%|█████▉    | 13/22 [08:53<05:41, 37.90s/it]\u001b[32m2023-06-17 19:52:29.948\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: facebookresearch/mmf\u001b[0m\n",
      "Processing repositories:  64%|██████▎   | 14/22 [08:56<03:38, 27.36s/it]\u001b[32m2023-06-17 19:52:32.943\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: mlflow/mlflow\u001b[0m\n",
      "Processing repositories:  68%|██████▊   | 15/22 [09:34<03:33, 30.57s/it]\u001b[32m2023-06-17 19:53:10.964\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: dask/dask\u001b[0m\n",
      "Processing repositories:  73%|███████▎  | 16/22 [10:05<03:03, 30.51s/it]\u001b[32m2023-06-17 19:53:41.341\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: streamlit/streamlit\u001b[0m\n",
      "Processing repositories:  77%|███████▋  | 17/22 [10:22<02:12, 26.44s/it]\u001b[32m2023-06-17 19:53:58.320\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: kedro-org/kedro\u001b[0m\n",
      "Processing repositories:  82%|████████▏ | 18/22 [10:28<01:21, 20.49s/it]\u001b[32m2023-06-17 19:54:04.963\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: geopandas/geopandas\u001b[0m\n",
      "Processing repositories:  86%|████████▋ | 19/22 [10:42<00:55, 18.61s/it]\u001b[32m2023-06-17 19:54:19.185\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: pandas-dev/pandas\u001b[0m\n",
      "Processing repositories:  91%|█████████ | 20/22 [12:34<01:32, 46.36s/it]\u001b[32m2023-06-17 19:56:10.210\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: astropy/astropy\u001b[0m\n",
      "Processing repositories:  95%|█████████▌| 21/22 [13:06<00:42, 42.20s/it]\u001b[32m2023-06-17 19:56:42.713\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mprocess_repositories\u001b[0m:\u001b[36m45\u001b[0m - \u001b[1mProcessing repository: sympy/sympy\u001b[0m\n",
      "Processing repositories: 100%|██████████| 22/22 [14:41<00:00, 40.07s/it]\n",
      "Matching issues found: 100%|██████████| 564/564 [00:00<00:00, 8388608.00it/s]\n",
      "\u001b[32m2023-06-17 19:58:17.804\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36msave_issues_to_file\u001b[0m:\u001b[36m66\u001b[0m - \u001b[1mIssues saved to file\u001b[0m\n",
      "\u001b[32m2023-06-17 19:58:17.805\u001b[0m | \u001b[1mINFO    \u001b[0m | \u001b[36m__main__\u001b[0m:\u001b[36mmain\u001b[0m:\u001b[36m103\u001b[0m - \u001b[1mTotal issues found: 564\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "def get_github_instance():\n",
    "    with open(\"../secrets/github_token.txt\", \"r\") as file:\n",
    "        token = file.read().strip()\n",
    "    logger.info(\"GitHub instance initialized\")\n",
    "    return Github(token)\n",
    "\n",
    "def get_repositories(github_instance, repo_list):\n",
    "    logger.info(f\"Fetching specified repositories\")\n",
    "    repos = []\n",
    "    for repo_path in repo_list:\n",
    "        repo_path = repo_path.replace(\" \", \"\")  # remove any spaces\n",
    "        try:\n",
    "            repos.append(github_instance.get_repo(repo_path))\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error fetching repo {repo_path}: {e}\")\n",
    "    return repos\n",
    "\n",
    "\n",
    "def get_issue_dict(issue, repo):\n",
    "    return {\n",
    "        'repo': repo.full_name,\n",
    "        'repo_url': repo.html_url,\n",
    "        'title': issue.title,\n",
    "        'description': issue.body, \n",
    "        'labels': [label.name for label in issue.labels],\n",
    "        'issue_url': issue.html_url,\n",
    "        'created_at': str(issue.created_at),\n",
    "        'comments': []\n",
    "    }\n",
    "\n",
    "def get_comment_dict(comment):\n",
    "    return {\n",
    "        'author': comment.user.login,\n",
    "        'body': comment.body,\n",
    "        'created_at': str(comment.created_at),\n",
    "    }\n",
    "\n",
    "def is_good_first_issue(issue):\n",
    "    return any(label.name.lower() == \"good first issue\" for label in issue.labels)\n",
    "\n",
    "def process_repositories(repos, progress_bar):\n",
    "    all_issues = {}\n",
    "    issue_count = 0\n",
    "    for repo in repos:\n",
    "        logger.info(f\"Processing repository: {repo.full_name}\")\n",
    "        try:\n",
    "            issues = repo.get_issues(state='open')\n",
    "            for issue in issues:\n",
    "                if is_good_first_issue(issue):\n",
    "                    issue_dict = get_issue_dict(issue, repo)\n",
    "                    comments = issue.get_comments()\n",
    "                    for comment in comments:\n",
    "                        comment_dict = get_comment_dict(comment)\n",
    "                        issue_dict['comments'].append(comment_dict)\n",
    "                    all_issues[issue.id] = issue_dict\n",
    "                    issue_count += 1\n",
    "        except Exception as e:\n",
    "            logger.error(f\"Error processing repo: {e}\")\n",
    "        finally:\n",
    "            progress_bar.update(1)\n",
    "    return all_issues, issue_count\n",
    "\n",
    "def save_issues_to_file(all_issues):\n",
    "    with open('issues.json', 'w') as f:\n",
    "        json.dump(all_issues, f)\n",
    "    logger.info(\"Issues saved to file\")\n",
    "\n",
    "def main():\n",
    "    g = get_github_instance()\n",
    "    repo_list = [\n",
    "        \"matplotlib / matplotlib\",\n",
    "        \"einsteinpy / einsteinpy\",\n",
    "        \"zulip / zulip\",\n",
    "        \"falconry / falcon\",\n",
    "        \"dmlc / gluon-nlp\",\n",
    "        \"mesonbuild  / meson\",\n",
    "        \"scipy / scipy\",\n",
    "        \"oilshell / oil\",\n",
    "        \"google / TensorNetwork\",\n",
    "        \"statsmodels / statsmodels\",\n",
    "        \"ray-project / ray\",\n",
    "        \"cython / cython\",\n",
    "        \"automl / auto-sklearn\",\n",
    "        \"facebookresearch / pythia\",\n",
    "        \"mlflow / mlflow\",\n",
    "        \"dask / dask\",\n",
    "        \"streamlit / streamlit\",\n",
    "        \"quantumblacklabs / kedro\",\n",
    "        \"geopandas / geopandas\",\n",
    "        \"pandas-dev / pandas\",\n",
    "        \"astropy / astropy\",\n",
    "        \"sympy / sympy\",\n",
    "    ]  # add the repos you want to process here\n",
    "\n",
    "    repos = get_repositories(g, repo_list)\n",
    "    repo_progress_bar = tqdm(total=len(repos), desc=\"Processing repositories\", dynamic_ncols=True)\n",
    "    all_issues, issue_count = process_repositories(repos, repo_progress_bar)\n",
    "    repo_progress_bar.close()\n",
    "    issue_progress_bar = tqdm(total=issue_count, desc=\"Matching issues found\", dynamic_ncols=True)\n",
    "    issue_progress_bar.update(issue_count)\n",
    "    issue_progress_bar.close()\n",
    "    save_issues_to_file(all_issues)\n",
    "    logger.info(f\"Total issues found: {issue_count}\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    main()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "trIAge",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
